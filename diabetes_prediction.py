# -*- coding: utf-8 -*-
"""Diabetes_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EDGaef_PeuGf55CbVUWB-sSolQDF570C
"""

# Commented out IPython magic to ensure Python compatibility.
#libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

#importing dataset
dataset=pd.read_csv('/content/diabetes.csv')

dataset

dataset.info()

#checking for any null data
dataset.isnull().sum()

dataset.describe()

#correlation plot of independent variables
plt.figure(figsize=(9,7))
sns.heatmap(dataset.corr(),annot=True,fmt=".3f")
plt.title("Correlation heatmap")

#exploring pregnancy and target variables
plt.figure(figsize=(9,7))
#plotting density function graph of the pregnancy and target variables

kde=sns.kdeplot(dataset["Pregnancies"][dataset["Outcome"]==1],color="Orange",shade=True)
kde=sns.kdeplot(dataset["Pregnancies"][dataset["Outcome"]==0],color="Green",shade=True)
kde.set_xlabel("Pregnancies")
kde.set_ylabel("Density")
kde.legend(["Positve","Negative"])

#exploring glucose and target variables
plt.figure(figsize=(9,7))
sns.violinplot(data=dataset,x="Outcome",y="Glucose",split=True, linewidth=2,inner="quart")

#exploring glucose and target variables
plt.figure(figsize=(9,7))
#plotting density function graph of the glucose and target variables

kde=sns.kdeplot(dataset["Glucose"][dataset["Outcome"]==1],color="Purple",shade=True)
kde=sns.kdeplot(dataset["Glucose"][dataset["Outcome"]==0],color="Black",shade=True)
kde.set_xlabel("Glucose")
kde.set_ylabel("Density")
kde.legend(["Positve","Negative"])

#replacing zero values with mean/median
#glucose
dataset["Glucose"]=dataset["Glucose"].replace(0,dataset["Glucose"].median())
#BloodPressure
dataset["BloodPressure"]=dataset["BloodPressure"].replace(0,dataset["BloodPressure"].median())
#BMI
dataset["BMI"]=dataset["BMI"].replace(0,dataset["BMI"].mean())
#SkinThickness
dataset["SkinThickness"]=dataset["SkinThickness"].replace(0,dataset["SkinThickness"].mean())
#Insulin
dataset["Insulin"]=dataset["Insulin"].replace(0,dataset["Insulin"].mean())

dataset

#splitting the dependent and independent variable
x=dataset.drop(["Outcome"],axis=1)
y=dataset["Outcome"]

x

#splitting the dataset into training and testing dataset
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.22, random_state=42)

X_train

#KNN
from sklearn.neighbors import KNeighborsClassifier

training_accuracy=[]
test_accuracy=[]
for n_neighbors in range(1,14):
  knn=KNeighborsClassifier(n_neighbors=n_neighbors)
  knn.fit(X_train,y_train)
  #seeing accuracy score
  training_accuracy.append(knn.score(X_train,y_train))
  test_accuracy.append(knn.score(X_test,y_test))

plt.plot(range(1,14),training_accuracy,label="training_accuracy")
plt.plot(range(1,14),test_accuracy,label="test_accuracy")
plt.ylabel("Accuracy")
plt.xlabel("n_neighbors")
plt.legend()

knn=KNeighborsClassifier(n_neighbors=12)
knn.fit(X_train,y_train)
print(knn.score(X_train,y_train),":Training Accuracy")
print(knn.score(X_test,y_test),":Testing Accuracy")

knn.predict([[0,130,78,35,0,22,0.872,17]])

from sklearn.tree import DecisionTreeClassifier
dt=DecisionTreeClassifier(random_state=8)
dt.fit(X_train,y_train)
print(dt.score(X_train,y_train),":Training Accuracy")
print(dt.score(X_test,y_test),":Testing Accuracy")

dt1=DecisionTreeClassifier(random_state=0,max_depth=6)
dt1.fit(X_train,y_train)
print(dt1.score(X_train,y_train),":Training Accuracy")
print(dt1.score(X_test,y_test),":Testing Accuracy")

from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(random_state=2)
mlp.fit(X_train,y_train)
print(mlp.score(X_train,y_train),":Training Accuracy")
print(mlp.score(X_test,y_test),":Testing Accuracy")

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train_scaled=sc.fit_transform(X_train)
X_test_scaled=sc.fit_transform(X_test)

mlp2=MLPClassifier(random_state=2)
mlp2.fit(X_train_scaled,y_train)
print(mlp2.score(X_train_scaled,y_train),":Training Accuracy")
print(mlp2.score(X_test_scaled,y_test),":Testing Accuracy")